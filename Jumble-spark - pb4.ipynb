{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import json\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window as W\n",
    "from pyspark.sql import functions as F\n",
    "from itertools import combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"jumble\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_row_index(df):\n",
    "    a1 = df.withColumn(\"row_idx\", monotonically_increasing_id())\n",
    "    windowSpec1 = W.orderBy(\"row_idx\")\n",
    "    b1 = a1.withColumn(\"row_idx\", row_number().over(windowSpec1))\n",
    "    return b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sortWord(word):\n",
    "    return ''.join(sorted(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function is to process the filtered input dataframe and separate the inputs into two categories\n",
    "# The first category is: input word has the same sorted word but the original word is not the same\n",
    "# The second category is: input word has no other input word to share the sorted world\n",
    "# The logic is: group the dataframe, if the count number for each group is larger than 1 , then the word is category 1\n",
    "# if the count number for each group is equal one, then the word is category 2\n",
    "\n",
    "def findDuplicateInputs(df):\n",
    "    \n",
    "    df1 = df.groupBy(\"sorted_word\").agg(F.max(\"freq\").alias(\"max_freq\"), \n",
    "                                        F.max(\"filter_index\"), F.count(\"word\").alias(\"count_number\")) \n",
    "    df2 = df1.where((col(\"count_number\") > 1))\n",
    "    for i in df2.collect():\n",
    "        if i.max_freq != 0:\n",
    "            df3 = df2.select(\"sorted_word\", \"max_freq\").alias(\"df2\").join(df.alias(\"df\"), (col(\"df2.sorted_word\") == col(\"df.sorted_word\")) &\\\n",
    "                                            (col(\"df2.max_freq\") ==col(\"df.freq\")))\\\n",
    "                                           .drop(col(\"df2.sorted_word\")).drop(col(\"input_word\")).drop(col(\"df2.max_freq\"))\n",
    "        if i.max_freq == 0:\n",
    "            df3 = df2.select(\"sorted_word\").alias(\"df2\").join(df.alias(\"df\"), col(\"df2.sorted_word\") == col(\"df.sorted_word\"))\\\n",
    "                                           .drop(col(\"df2.sorted_word\")).drop(col(\"input_word\"))\n",
    "                \n",
    "    df2_1 = df1.where((col(\"count_number\") == 1)) \n",
    "    df3_1 = df2_1.select(\"sorted_word\").alias(\"df2_1\").join(df.alias(\"df\"), col(\"df2_1.sorted_word\") == col(\"df.sorted_word\"))\\\n",
    "                                       .drop(col(\"df2_1.sorted_word\")).drop(col(\"input_word\"))\n",
    "    return df3, df3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# those functions are used to apply the index to the word, ex: \"GLAND\" 's filter index is [1,3,4], function getCharList is used to\n",
    "# apply the index to the word and the get a combined string: 'lnd'\n",
    "\n",
    "# function getDuplicateChar is used to apply the index to the category 1 word and get a combined string list\n",
    "\n",
    "def getCharList(lis):\n",
    "    \n",
    "    input_list = []\n",
    "    for i in lis:\n",
    "        word = i[0]\n",
    "        filter_index = i[1]\n",
    "        \n",
    "        temp_list = [word[i] for i in filter_index]\n",
    "        input_list.extend(temp_list)\n",
    "    return sortWord(input_list)\n",
    "\n",
    "def getDuplicateChar(lis):\n",
    "    \n",
    "    input_list = []\n",
    "    for i in lis:\n",
    "            word = i[0]\n",
    "            filter_index = i[1]\n",
    "            temp_list = sortWord([word[i] for i in filter_index])\n",
    "            input_list.append(temp_list)\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCharList2(lis):\n",
    "\n",
    "    input_list2 = []\n",
    "    for i in lis:\n",
    "        word1 = i[0]\n",
    "        filter_index1 = i[1]\n",
    "        \n",
    "        word2=i[3]\n",
    "        filter_index2 = i[4]\n",
    "        \n",
    "        temp_list1 = [word1[i] for i in filter_index1]\n",
    "        temp_list2 = [word2[i] for i in filter_index2]\n",
    "        temp_list = sortWord(temp_list1 + temp_list2)\n",
    "        input_list2.append(temp_list)\n",
    "        \n",
    "    return input_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the situation where the inputs have mutiple words to share the same sorted words, but there is just one kind.\n",
    "# for example: A1, A2, A3 has the same sorted word A, in input_duplicates_df, the distinct column is 1\n",
    "\n",
    "def getFinalInputChar1(lis):\n",
    "    \n",
    "    final_inut_char_list = []\n",
    "    lis1 = getDuplicateChar(lis)\n",
    "    lis2 = set(lis1)\n",
    "    \n",
    "    input_only_one_char = getCharList(input_only_one_list)\n",
    "    \n",
    "    for i in lis2:\n",
    "        temp = sortWord(i+input_only_one_char)\n",
    "        final_inut_char_list.append(temp)\n",
    "        \n",
    "    return final_inut_char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ex: In input_duplicates_df, A1, A2, A3 shared the sorted word: A, B1, B2 shared the sorted word B,so the disctinct number is 2\n",
    "# the possiblility for inputs now is: A1B1, A1B2, A2B1, A2B2, A3B1, A3B2. then filter by the index, get rid duplicates, and then \n",
    "# add the inputs in input_only_one_list to get the final input string\n",
    "\n",
    "def getFinalInputChar2(lis):\n",
    "    \n",
    "    temp = []\n",
    "    final_inut_char_list = []\n",
    "    \n",
    "    for i in lis:\n",
    "        for j in lis:\n",
    "            if  i != j and i[2] != j[2]:\n",
    "                temp.append(i+j)\n",
    "                \n",
    "    temp1 = getCharList2(temp)\n",
    "    temp2 = set(temp1)\n",
    "    \n",
    "    input_only_one_char = getCharList(input_only_one_list)\n",
    "    for i in temp2:\n",
    "        temp3 = sortWord(i+input_only_one_char)\n",
    "        final_inut_char_list.append(temp3)\n",
    "    \n",
    "    return final_inut_char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOutputWordPara(input_df):\n",
    "    \n",
    "    output_word_number_df = input_df.where(col(\"input_word\") == \"RESULT_LENGTH\")\n",
    "    output_word_index = output_word_number_df.collect()[0].filter_index\n",
    "    output_word_number = len(output_word_index)\n",
    "    \n",
    "    return output_word_index, output_word_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter the freq_dict list based on the output words length: for ex: if the output index is [3,4,5], which means filter the freq_dict \n",
    "# with length =3, length =4, length =5, after the filtering, the result is only have the possible element with the word length as the input need\n",
    "\n",
    "def getFilteredList(freq_dict,output_word_index, output_word_number):\n",
    "    \n",
    "    temp = []\n",
    "    res_list = []\n",
    "    freq_dict_list = [[i.word, i.freq] for i in freq_dict.collect()]\n",
    "    \n",
    "    for i in range(0, output_word_number):\n",
    "        for j in freq_dict_list:\n",
    "            if len(j[0]) == output_word_index[i]:\n",
    "                temp.append(j)\n",
    "            \n",
    "    for i in temp:\n",
    "        if i not in res_list:\n",
    "            res_list.append(i)       \n",
    "    \n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ouput word number =1\n",
    "def getFinalResult1(final_inut_char_list):\n",
    "    \n",
    "    for i in final_inut_char_list:\n",
    "        for j in res_list:\n",
    "            if sortWord(j[0]) == i and j[1] != 0 and j[1] <=1200:\n",
    "                print(j)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for output word number = 2\n",
    "def getFinalResult2(final_inut_char_list):\n",
    "    \n",
    "    for i in final_inut_char_list:\n",
    "        for j in comb:\n",
    "            if len(j[0][0])==output_word_index[0] and len(j[1][0])== output_word_index[1]\\\n",
    "            and j[0][1]+j[1][1] !=0 and j[1][1] <=1200\\\n",
    "            and j[1][1] !=0 and sortWord(j[0][0] + j[1][0]) == i:\n",
    "                print(j)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for output word number =3\n",
    "def getFinalResult3(final_inut_char_list):\n",
    "    \n",
    "    for i in final_inut_char_list:\n",
    "        for j in comb:\n",
    "            if len(j[0][0])==output_word_index[0] and len(j[1][0])==output_word_index[1] and len(j[2][0])==output_word_index[2]\\\n",
    "            and j[0][1]+j[1][1]+j[2][1] !=0 and j[2][1] <=1200\\\n",
    "            and j[2][1] != 0 and sortWord(j[0][0] + j[1][0] +j[2][0]) == i:\n",
    "                print(j)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the freq_dict file and create a dataframe\n",
    "input_file =open(\"freq_dict.json\").read()\n",
    "input_data = json.loads(input_file)\n",
    "\n",
    "schema = StructType([StructField('word', StringType(), False),\n",
    "                     StructField('freq', IntegerType(), False)])\n",
    "\n",
    "freq_dict_df = spark.createDataFrame(input_data.items(),schema)\n",
    "\n",
    "sort_word = udf(lambda x:sortWord(x.lower()))\n",
    "\n",
    "\n",
    "#add a index column\n",
    "freq_dict = add_row_index(freq_dict_df)\n",
    "freq_dict = freq_dict.withColumn(\"sorted_word\", sort_word(freq_dict.word))\n",
    "\n",
    "#create a view\n",
    "freq_dict.createOrReplaceTempView(\"freq_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#load the json inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_input =open(\"input4.json\").read()\n",
    "user_data = json.loads(user_input)\n",
    "\n",
    "input_shcema = StructType([StructField('input_word', StringType(), False),\n",
    "                           StructField('filter_index', ArrayType(IntegerType()), False)])\n",
    "\n",
    "input_df = spark.createDataFrame(user_data.items(),input_shcema)\n",
    "\n",
    "# add a soretd word column\n",
    "input_df = add_row_index(input_df)\n",
    "input_df = input_df.withColumn(\"sorted_word\", sort_word(input_df.input_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_word_df = input_df.where(col(\"input_word\") != \"RESULT_LENGTH\")\n",
    "\n",
    "# join input_wprd_df with freq_dict to filter freq_dict with inputs\n",
    "# the result join_df is a filtered dataframe \n",
    "\n",
    "join_df = freq_dict.alias(\"a\").join(input_word_df.alias(\"b\"), col(\"a.sorted_word\") == col(\"b.sorted_word\"))\n",
    "join_df = join_df.select(\"word\",\"freq\", \"a.sorted_word\", \"input_word\", \"filter_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate the inputs into category 1 and category 2\n",
    "# input_duplicates_df is category 1 (have mutilple inputs share a sorted word)\n",
    "# input_only_one_df is category 2\n",
    "\n",
    "input_duplicates_df, input_only_one_df = findDuplicateInputs(join_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sorted_number is used to determine how to combine category 1 and category 2 inputs together to get the final input string\n",
    "\n",
    "sorted_number_df = input_duplicates_df.agg(countDistinct(col(\"sorted_word\")).alias(\"sorted_number\"))\n",
    "sorted_number = sorted_number_df.collect()[0].sorted_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_only_one_list = [[i.word, i.filter_index] for i in input_only_one_df.collect()]\n",
    "input_duplicate_list = [[i.word, i.filter_index, i.sorted_word] for i in input_duplicates_df.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dinky', [0, 1]], ['encore', [1, 3]], ['devout', [0, 5]]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_only_one_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if sorted_number ==1:\n",
    "    \n",
    "    final_inut_char_list = getFinalInputChar1(input_duplicate_list)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    final_inut_char_list = getFinalInputChar2(input_duplicate_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ddgilnot', 'addiinot']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_inut_char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Filter the freq_dict_list based on user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output_word_index means the output word length\n",
    "# output_word_number means the how many words in output\n",
    "\n",
    "output_word_index, output_word_number = getOutputWordPara(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_word_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_list = getFilteredList(freq_dict,output_word_index, output_word_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get combination from the filter list with output required length\n",
    "\n",
    "comb = combinations(res_list, output_word_number) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['addition', 1092]\n"
     ]
    }
   ],
   "source": [
    "if output_word_number == 1:\n",
    "    result_1 = getFinalResult1(final_inut_char_list)\n",
    "    \n",
    "if output_word_number == 2:\n",
    "    result_2 = getFinalResult2(final_inut_char_list)\n",
    "    \n",
    "if output_word_number == 3:\n",
    "    result_3 = getFinalResult3(final_inut_char_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
